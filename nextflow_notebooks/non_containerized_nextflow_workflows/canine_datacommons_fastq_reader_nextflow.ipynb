{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c9f5ca-6244-470d-bddb-681f70d7e229",
   "metadata": {},
   "source": [
    "*This tutorial provides a summarized explanation of Nextflow, derived from the original [Nextflow training documents](https://training.nextflow.io/). In addition, it also showcases an interactive example of how to utilize Nextflow in BRH adapted from the [Canine Data Commons FASTQ Reader tutorial](https://brh.data-commons.org/dashboard/Public/notebooks/canine_datacommons_fastq_reader.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bdca20-1369-4b62-857f-4ab0b19fae18",
   "metadata": {},
   "source": [
    "In order for this tutorial to be able to download data from Gen3, access to the Tutorial CANINE Google Login must be authorized under the Profile page in BRH. Pulling the data from gen3 may not work on your local machine. [Read more](https://brh.data-commons.org/dashboard/Public/index.html#LinkingAccessTo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b1378c-5bbf-4b67-97ca-79e092521694",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Nextflow Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dedd8dd-ebd8-4d0e-aac9-6072ce2f4f1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Why Use Nextflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884692a-9af0-49f7-ac92-f8efbfe761df",
   "metadata": {},
   "source": [
    "Nextflow is a tool that helps to easily create workflows for data-heavy computations. It's built around the idea that Linux, with its many command-line and scripting tools, can be used as a language to create data science pipelines.\n",
    "\n",
    "Nextflow allows you to define complex interactions between programming languages and gives you a sophisticated parallel computing environment in which to write pipelines (termed workflows). It's key features include:\n",
    "* Workflow portability and reproducibility\n",
    "* Scalability of parallelization and deployment\n",
    "* Integration of existing tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90939c02-3405-4779-8c9b-5aff028038c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Processes and Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3bf59-80e1-4e16-9ac7-7b2bab3d2217",
   "metadata": {},
   "source": [
    "A Nextflow workflow is created by connecting different processes. Each process can be written in any scripting language that Linux can run (like Bash, Perl, Ruby, Python, etc.). These processes run independently and do not share any common state that can be written to.\n",
    "\n",
    "The only way these processes can talk to each other is through asynchronous queues called channels. Any process can define one or more channels as an input and output. The way these processes interact, and therefore the workflow itself, is determined by these input and output declarations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ad1a6-46d6-4b7c-9757-c3de0a7cd0d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execution Abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afedc7-a964-4f77-accb-ef514b8dae47",
   "metadata": {},
   "source": [
    "While a process defines what command or script should be run, the executor determines how that script is run on the target platform. Unless specified otherwise, processes are run on your local computer.\n",
    "\n",
    "However, for real-world workflows, a cloud platform is often needed. Nextflow provides a separation between the logic of the workflow and the system on which it runs. This means you can create a workflow that runs on your computer, a server, or the cloud, without needing any changes. You just need to define the target platform in the configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0534fb-475f-4be0-8531-b297ace0af5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scripting Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa134dd6-7900-42c1-9dfd-b2f483a2d00c",
   "metadata": {},
   "source": [
    "Nextflow scripting is an extension of the Groovy programming language, which itself is a subset of Java. Groovy is like a simplified version of Java, making it easier and more approachable to write code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc302c3-b375-4e43-b464-e664d16b732f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example Gen3 Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4729a651-4b47-40d5-928c-104aa30c5708",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60214f6a-3233-4e92-9a01-6058fcb4b178",
   "metadata": {},
   "source": [
    "Now let's get into the specifics of how Nextflow works. The most essential component of a Nextflow workflow is the main .nf Nextflow script file. Here is where the main flow of the workflow is set. We will slowly build up the components of this file in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9219c1-3714-446c-adf4-e8d6bdac1968",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/usr/bin/env nextflow\n",
    "...\n",
    "workflow {\n",
    "    files = DownloadFastqFile()\n",
    "    files.flatten().set {input_files}\n",
    "    AnalyzeFastqFile(input_files)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa29550-0ff5-48a8-ae8a-d3a345c75ebe",
   "metadata": {},
   "source": [
    "The first line of a Nextflow script file is a shebang. It's a special type of comment used in scripts to specify what interpreter should be used to execute the script.\n",
    "\n",
    "In this case, `#!/usr/bin/env nextflow` tells the system to execute the script using the `nextflow` interpreter. The `env` command helps locate the `nextflow` interpreter within the system's PATH. If you are using a Nextflow workspace in BRH, this setup has already been properly done. If not, refer to https://www.nextflow.io/docs/latest/getstarted.html for setup instructions.\n",
    "\n",
    "The workflow is the final component of the Nextflow script and outlines the primary steps in the pipeline:\n",
    "\n",
    "1. `files = DownloadFastqFile()`: This line executes the `DownloadFastqFile` process, which is defined earlier in the script (not shown here for simplicity). The results of this process, which could be multiple files, are stored in the variable `files`.\n",
    "\n",
    "2. `files.flatten().set {input_files}`: The `flatten()` operator transforms the nested collection of files into a flat list (where each file can then be fed independently into the next process). This flattened list of files is then converted into a Nextflow channel and stored in `input_files`. A Nextflow channel is a mechanism that allows data to be passed between processes.\n",
    "\n",
    "3. `AnalyzeFastqFile(input_files)`: This line calls the `AnalyzeFastqFile` process, using the output of `DownloadFastqFile` (the flattened list of files) as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7b26a-4a1f-49fd-adde-a1c740aabd73",
   "metadata": {},
   "source": [
    "The workflow showcased here consists of two separate processes. The first of these is `DownloadFastqFile`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc7f2a-2d9d-45ea-9d69-96e79e89becb",
   "metadata": {},
   "source": [
    "```bash\n",
    "process DownloadFastqFile {\n",
    "\n",
    "    // Move the outputs of DownloadFastqFile to the results directory in\n",
    "    // the base workflow directory\n",
    "\n",
    "    conda './environment.yml' // path to your environment.yml file\n",
    "\n",
    "    output:\n",
    "    path(\"*.fastq\")\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    gen3 drs-pull object \"${params.fastq_guid}\"\n",
    "    for file in \\$(ls | grep .fastq.gz); do\n",
    "        gunzip \"\\$file\"\n",
    "    done\n",
    "    \"\"\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd3cf6-592e-4f67-8125-a0c8308a9746",
   "metadata": {},
   "source": [
    "This process consists of several major components:\n",
    "\n",
    "1. `conda './environment.yml'`: This is an optional line which tells Nextflow to use the conda environment specified in the 'environment.yml' file to run this process (or create it if it doesn't already exist). Conda is a package and environment management system, and using this statement ensures that the correct dependencies are installed and used for this process. It is also possible to specify the conda environment to be used in the `nextflow.config` file instead (see below for more details on the Nextflow configuration file).\n",
    "\n",
    "2. `output: path(\"*.fastq\")`: This line specifies what the process will output. In this case, the process outputs one or more fastq files pulled from gen3. Since `*` is used in the filename Nextflow will take any files outputted by this process which end in .fastq as the outputs of the process.\n",
    "\n",
    "3. `script:`: This begins the section where the commands to be run by this process are defined. In this case the commands are a bash script to download the `params.fastq_guid` (which is a parameter to the nextflow workflow which is given in the configuration file - more details below) file from gen3 and a loop to go through all the files ending in .fastq.gz that were pulled and unzip them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90093015-71e2-4704-bd36-e10fe85f8075",
   "metadata": {},
   "source": [
    "The `./environment.yml` file being used to specify the conda environment installs the needed dependencies for the python scripts being run. Read more about conda environment files [here](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345a7d88-3486-4da1-aaad-74d9a4936f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile environment.yml\n",
    "name: canine\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.9\n",
    "  - pip\n",
    "  - pip:\n",
    "    - gen3==4.20\n",
    "    - bioinfokit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59941ea-c86e-4fe0-9a6b-e57e30ddbc15",
   "metadata": {},
   "source": [
    "*Note the `%%writefile environment.yml` line tells Jupyter Notebook to write the cell to a file rather than running the code in Jupyter Notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06016bb7-5398-494b-bfd0-eefd48ee1b55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nextflow.config\n"
     ]
    }
   ],
   "source": [
    "%%writefile nextflow.config\n",
    "// enables the processes to be run in a conda environment\n",
    "conda.enabled = true\n",
    "\n",
    "params {\n",
    "    fastq_guid = \"dg.C78ne/4527012c-3a5f-481d-820c-da7b77a26b48\" // GUID for fastq file\n",
    "    max_records = 10 // max records to process\n",
    "    endpoint = \"https://caninedc.org\"\n",
    "    refresh_file = \"/home/jovyan/.gen3/credentials.json\"\n",
    "}\n",
    "\n",
    "process {\n",
    "    conda {\n",
    "        envCreate = true\n",
    "        envName = 'canine'\n",
    "        // If the environment does not exist, Nextflow will create it using the specified YAML file\n",
    "        envFile = 'environment.yml'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3103353",
   "metadata": {},
   "source": [
    "The Nextflow configuration file gives additional setup details for the Nextflow workflow. In this case, it specifies that Conda is to be used for setting up the environments for the individuals processes and sets up some default parameters for the Nextflow script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd6128",
   "metadata": {},
   "source": [
    "These parameters can be used within the script and can also be overridden when you run the script. \n",
    "\n",
    "You can set or override the parameters when you run the script by passing them as command line arguments with the `--` prefix. \n",
    "\n",
    "For example, to run the script with different values for `refresh_file` and `max_records`, you would use the following command:\n",
    "\n",
    "```bash\n",
    "nextflow run canine.nf --refresh_file=\"/home/josh/.gen3/credentials.json\" --max_records=20\n",
    "```\n",
    "\n",
    "`nextflow run canine.nf` is the ordinary syntax for running the script, `/home/josh/.gen3/credentials.json` is the new value for `refresh_file` and `20` is the new value for `max_records`. The `max_records` parameter is accessed in the Nextflow script itself through `{params.max_records}`.\n",
    "\n",
    "This is one of the features that makes Nextflow powerful for pipeline scripting. By using parameters, the same script can be used with different data or settings without any changes to the script itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8b5830-0fce-4f34-b6fe-70b962cd1cc9",
   "metadata": {},
   "source": [
    "Nextflow configuration files can specify variables for the script being run or specific settings for how to run the script. Read more about Nextflow configuration files at https://www.nextflow.io/docs/latest/config.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef10ae-43a4-4383-b1e9-076f061fcd6a",
   "metadata": {},
   "source": [
    "```bash\n",
    "process AnalyzeFastqFile {\n",
    "\n",
    "    // Copy the outputs of AnalyzeFastqFile to the results directory in\n",
    "    // the base workflow directory\n",
    "    publishDir \"${baseDir}/results\", mode: 'copy'\n",
    "    \n",
    "    conda './environment.yml' // path to your environment.yml file\n",
    "\n",
    "    input:\n",
    "    path(input_file)\n",
    "\n",
    "    output:\n",
    "    path(\"${input_file}_analysis.txt\")\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    python3 ${baseDir}/analyze_fastq.py ${params.endpoint} ${params.refresh_file} ${input_file} ${params.max_records}\n",
    "    \"\"\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33650e1c-6981-4296-a313-33f8736445cc",
   "metadata": {},
   "source": [
    "The second process in this workflow takes the file specified by the parameter `params.fastq_file` and runs the Python script `analyze_fastq.py` which can be found in the same directory as the Nextflow script (this is indicated by the `${baseDir}/` before the name of the Python script to be run).\n",
    "\n",
    "The `analyze_fastq.py` script is run with four command-line parameters each of which is specified by one of the parameters specified in the configuration file. Nextflow automatically stores the path for the input file to the process inside the input file variable which can then be referenced in the output file name as well as given as a command line parameter to the python script.\n",
    "\n",
    "Lastly, the AnalyzeFastqFile process also specifies `${input_file}_analysis.txt` as the output of the `analyze_fastq.py`. The actual code to create the file is within the Python script itself but this section indicates to the process to expect a text file named `${input_file}_analysis.txt` to be written by the Python script. The line `publishDir \"${baseDir}/results\", mode: 'copy'` indicates for Nextflow to copy the `${params.fastq_file}_analysis.txt` file produced by this process to the results folder in the same main directory as the Nextflow script (`${baseDir}`). This line will also automatically create a results folder for the output to be copied into if one doesn't already exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7bee7-bf44-4c3a-be65-a6e535b4cb85",
   "metadata": {},
   "source": [
    "The Python code for the AnalyzeFastqFile process is given in `analyze_fastq.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e51afc1-d7e8-49ac-be04-a0ece8140e52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting analyze_fastq.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile analyze_fastq.py\n",
    "import argparse\n",
    "from gen3.file import Gen3File\n",
    "from gen3.query import Gen3Query\n",
    "from gen3.auth import Gen3Auth\n",
    "from gen3.submission import Gen3Submission\n",
    "from gen3.index import Gen3Index\n",
    "from bioinfokit.analys import fastq\n",
    "\n",
    "# create the top-level parser\n",
    "parser = argparse.ArgumentParser(prog='analyze_fastq')\n",
    "parser.add_argument('endpoint', type=str, help='The endpoint.')\n",
    "parser.add_argument('refresh_file', type=str, help='The refresh file.')\n",
    "parser.add_argument('fastq_file', type=str, help='The FASTQ file to analyze.')\n",
    "parser.add_argument('record_limit', type=float, help='The maximum number of records to process.')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "endpoint = args.endpoint\n",
    "auth = Gen3Auth(endpoint, refresh_file=args.refresh_file)\n",
    "sub = Gen3Submission(endpoint, auth)\n",
    "file = Gen3File(endpoint, auth)\n",
    "\n",
    "programs = sub.get_programs()\n",
    "\n",
    "records = fastq.fastq_reader(file=args.fastq_file)\n",
    "counter = 0\n",
    "output_file = open(args.fastq_file + \"_analysis.txt\", \"w\")\n",
    "\n",
    "for record in records:\n",
    "    if counter < args.record_limit:\n",
    "        _, sequence, _, quality = record\n",
    "        base_count = {'A': sequence.count('A'), 'C': sequence.count('C'), 'G': sequence.count('G'), 'T': sequence.count('T')}\n",
    "        output_file.write(f\"{sequence}, {quality}, {base_count}\\n\")\n",
    "    else:\n",
    "        break\n",
    "    counter += 1\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa76588f-b9b8-4f24-9447-9bbf69b4725c",
   "metadata": {},
   "source": [
    "This script, `analyze_fastq.py`, is used to analyze a FASTQ file and create a textual analysis output file. This analysis consists of the sequence, quality, and base counts for a specified number of records. The FASTQ file to be analyzed, the number of records to be analyzed, and a few more parameters are passed to the script as command-line arguments.\n",
    "\n",
    "Let's go through the script line by line:\n",
    "\n",
    "1. `import argparse`: This line imports the `argparse` module, which provides functions to facilitate the parsing of command-line arguments.\n",
    "\n",
    "2. The script then imports several modules from the `gen3` and `bioinfokit` packages. These packages are used to interact with a Gen3 data repository and analyze the FASTQ file respectively.\n",
    "\n",
    "3. The `argparse.ArgumentParser` function is used to create a parser object. This object will hold all the information necessary to parse the command-line arguments.\n",
    "\n",
    "4. `parser.add_argument` is then used to specify which command-line options the program is expecting. In this case, it is expecting four positional arguments: `endpoint`, `refresh_file`, `fastq_file`, and `record_limit`.\n",
    "\n",
    "5. `args = parser.parse_args()`: This line parses the command-line arguments and returns them as an `argparse.Namespace` object. The arguments are then accessed as attributes of this object.\n",
    "\n",
    "6. `auth = Gen3Auth(endpoint, refresh_file=args.refresh_file)`: This line creates a `Gen3Auth` object. This represents the user's authorization to access the Gen3 data repository. The `refresh_file` argument should point to a file containing the user's credentials.\n",
    "\n",
    "7. `sub = Gen3Submission(endpoint, auth)`: This line creates a `Gen3Submission` object which can be used to submit data to the Gen3 repository.\n",
    "\n",
    "8. `file = Gen3File(endpoint, auth)`: This line creates a `Gen3File` object, representing the file to be analyzed.\n",
    "\n",
    "9. `programs = sub.get_programs()`: This line gets a list of programs from the Gen3 repository.\n",
    "\n",
    "10. `records = fastq.fastq_reader(file=args.fastq_file)`: This line reads the records from the FASTQ file, which is one of the command-line arguments.\n",
    "\n",
    "11. An output file is opened for writing. The output file's name is the same as the input FASTQ file, with \"_analysis.txt\" appended to it.\n",
    "\n",
    "12. The script then enters a for loop, iterating over the FASTQ records. For each record, it splits the record into its sequence and quality components. It then counts the number of each base (A, C, G, T) in the sequence. This information is written to the output file. The loop stops when the number of processed records equals the `record_limit` argument.\n",
    "\n",
    "13. `output_file.close()`: Finally, the script closes the output file.\n",
    "\n",
    "In summary, this script (and by extension, the `AnalyzeFastqFile` process which calls it) reads a FASTQ file, analyzes the sequence and quality of a certain number of records, and writes the results to a new file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08daf31f-ba0f-49e3-9328-4c9f486d06d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Putting all sections of the Nextflow script together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1afb713d-83b3-40ef-baa6-553753969f53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting canine.nf\n"
     ]
    }
   ],
   "source": [
    "%%writefile canine.nf\n",
    "#!/usr/bin/env nextflow\n",
    "\n",
    "process DownloadFastqFile {\n",
    "\n",
    "    // Move the outputs of DownloadFastqFile to the results directory in\n",
    "    // the base workflow directory\n",
    "\n",
    "    conda './environment.yml' // path to your environment.yml file\n",
    "\n",
    "    output:\n",
    "    path(\"*.fastq\")\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    gen3 drs-pull object \"${params.fastq_guid}\"\n",
    "    for file in \\$(ls | grep .fastq.gz); do\n",
    "        gunzip \"\\$file\"\n",
    "    done\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "process AnalyzeFastqFile {\n",
    "\n",
    "    // Copy the outputs of AnalyzeFastqFile to the results directory in\n",
    "    // the base workflow directory\n",
    "    publishDir \"${baseDir}/results\", mode: 'copy'\n",
    "    \n",
    "    conda './environment.yml' // path to your environment.yml file\n",
    "\n",
    "    input:\n",
    "    path(input_file)\n",
    "\n",
    "    output:\n",
    "    path(\"${input_file}_analysis.txt\")\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    python3 ${baseDir}/analyze_fastq.py ${params.endpoint} ${params.refresh_file} ${input_file} ${params.max_records}\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "workflow {\n",
    "    files = DownloadFastqFile()\n",
    "    files.flatten().set {input_files}\n",
    "    AnalyzeFastqFile(input_files)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c19fd-6753-4ffc-9565-9c06fc4baeeb",
   "metadata": {},
   "source": [
    "To edit and re-run the Nextflow script, make sure to execute the above cell again to rewrite the Nextflow script file and then run the code block following this to re-run the script itself. It may also be necessary to delete the work and results directory between runs since the large size of the downloaded `SRR7012463_1.fastq` file can quickly exhaust memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcdaac5-2b7b-4c5c-bd1c-e088658e6787",
   "metadata": {},
   "source": [
    "Nextflow can create the conda environment if it doesn't already exist before running but doing so can obscur any errors that may be encountered in the environment creation process. To simplify this, we here first create the Conda environment and subsequently run the Nextflow workflow. Creating the Conda environment for the first time may take 5 or more minutes (though the time required is quite variable). This line will produce an error if it is run when a conda environment named `canine` already exists (such as if this line is run more than once). In that case running the command `conda remove --name canine --all` in the terminal will remove the pre-existing conda environment so a new one can be created. If you are in the BRH workspaces, a terminal may be opened by going to `File -> New -> Terminal`. If you are running this notebook more than once the correct conda environment will already exist after the first time it is created so this line need not be run more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b58501-7ef8-4afd-8326-5ffc6073691d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.1.0\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Installing pip dependencies: \\ Ran pip subprocess with arguments:\n",
      "['/opt/conda/envs/canine/bin/python', '-m', 'pip', 'install', '-U', '-r', '/home/jovyan/condaenv.u83xlnk2.requirements.txt', '--exists-action=b']\n",
      "Pip subprocess output:\n",
      "Collecting gen3==4.20 (from -r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for gen3==4.20 from https://files.pythonhosted.org/packages/72/9f/2d45202bcb1262e78f7a724f3483b598dcdda37bec9fee66236c5114f6f1/gen3-4.20.0-py3-none-any.whl.metadata\n",
      "  Using cached gen3-4.20.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting bioinfokit (from -r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Using cached bioinfokit-2.1.1-py3-none-any.whl\n",
      "Collecting aiofiles<0.9.0,>=0.8.0 (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached aiofiles-0.8.0-py3-none-any.whl (13 kB)\n",
      "Collecting aiohttp (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/5b/8d/821fcb268cfc056964a75da3823896b17eabaa4968a2414121bc93b0c501/aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting backoff (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting cdislogging<2.0.0,>=1.1.0 (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached cdislogging-1.1.1-py3-none-any.whl\n",
      "Collecting click (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/1a/70/e63223f8116931d365993d4a6b7ef653a4d920b41d03de7c59499962821f/click-8.1.6-py3-none-any.whl.metadata\n",
      "  Using cached click-8.1.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting dataclasses-json (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for dataclasses-json from https://files.pythonhosted.org/packages/97/5f/e7cc90f36152810cab08b6c9c1125e8bcb9d76f8b3018d101b5f877b386c/dataclasses_json-0.5.14-py3-none-any.whl.metadata\n",
      "  Using cached dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting drsclient<0.3.0,>=0.2.2 (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached drsclient-0.2.3-py3-none-any.whl\n",
      "Collecting httpx (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for httpx from https://files.pythonhosted.org/packages/ec/91/e41f64f03d2a13aee7e8c819d82ee3aa7cdc484d18c0ae859742597d5aa0/httpx-0.24.1-py3-none-any.whl.metadata\n",
      "  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting humanfriendly (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting indexclient (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached indexclient-2.2.1-py3-none-any.whl\n",
      "Collecting jsonschema (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for jsonschema from https://files.pythonhosted.org/packages/a1/ba/28ce987450c6afa8336373761193ddaadc1ba2004fbf23a6407db036f558/jsonschema-4.18.4-py3-none-any.whl.metadata\n",
      "  Using cached jsonschema-4.18.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting pandas<2.0.0,>=1.4.2 (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "Collecting pypfb<1.0.0 (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for pypfb<1.0.0 from https://files.pythonhosted.org/packages/87/55/243988a1ed6208f6299a10ed74cc399af42af6d323f8cf20d8a6108ad690/pypfb-0.5.26-py3-none-any.whl.metadata\n",
      "  Using cached pypfb-0.5.26-py3-none-any.whl.metadata (775 bytes)\n",
      "Collecting python-dateutil (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting requests (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for requests from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm<5.0.0,>=4.61.2 (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting urllib3<2.0.0 (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for urllib3<2.0.0 from https://files.pythonhosted.org/packages/c5/05/c214b32d21c0b465506f95c4f28ccbcba15022e000b043b72b3df7728471/urllib3-1.26.16-py2.py3-none-any.whl.metadata\n",
      "  Using cached urllib3-1.26.16-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Collecting xmltodict<0.14.0,>=0.13.0 (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting numpy (from bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/69/1f/c95b1108a9972a52d7b1b63ed8ca70466b59b8c1811bd121f1e667cc45d8/numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting matplotlib (from bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/47/b9/6c0daa9b953a80b4e6933bf6a11a2d0633f257e84ee5995c5fd35de564c9/matplotlib-3.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached matplotlib-3.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting scipy (from bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/08/25/035fe07fc32c5a8b314f882faa9d4817223fa5faf524d3fedcf17a4b9d22/scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
      "Collecting scikit-learn (from bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/d4/61/966d3238f6cbcbb13350d31bd0accfc5efdf9e349cd2a42d9761b8b67a18/scikit_learn-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scikit_learn-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn (from bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Collecting matplotlib-venn (from bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Using cached matplotlib_venn-0.11.9-py3-none-any.whl\n",
      "Collecting tabulate (from bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting statsmodels (from bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Using cached statsmodels-0.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
      "Collecting textwrap3 (from bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Using cached textwrap3-0.9.2-py2.py3-none-any.whl (12 kB)\n",
      "Collecting adjustText (from bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Using cached adjustText-0.8-py3-none-any.whl (9.1 kB)\n",
      "Collecting asyncio<4.0.0,>=3.4.3 (from drsclient<0.3.0,>=0.2.2->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached asyncio-3.4.3-py3-none-any.whl (101 kB)\n",
      "Collecting backoff (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached backoff-1.11.1-py2.py3-none-any.whl (13 kB)\n",
      "Collecting httpx (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "Collecting certifi (from httpx->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for certifi from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
      "  Using cached certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore<0.17.0,>=0.15.0 (from httpx->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3 (from httpx->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting sniffio (from httpx->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<2.0.0,>=1.4.2->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting PyYAML<6.0.0,>=5.3.1 (from pypfb<1.0.0->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
      "Collecting click (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting dictionaryutils<4.0.0,>=3.4.3 (from pypfb<1.0.0->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached dictionaryutils-3.4.6-py3-none-any.whl\n",
      "Collecting fastavro<1.9.0,>=1.8.2 (from pypfb<1.0.0->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for fastavro<1.9.0,>=1.8.2 from https://files.pythonhosted.org/packages/d1/32/12202e93d0cac2fe6a38066a1264391fdbfd8fcfea446846d9dff4f68c53/fastavro-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached fastavro-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting gdcdictionary<2.0.0,>=1.2.0 (from pypfb<1.0.0->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached gdcdictionary-1.2.0-py3-none-any.whl\n",
      "Collecting python-json-logger<0.2.0,>=0.1.11 (from pypfb<1.0.0->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached python_json_logger-0.1.11-py2.py3-none-any.whl\n",
      "Collecting attrs>=17.3.0 (from aiohttp->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer<4.0,>=2.0 (from aiohttp->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for charset-normalizer<4.0,>=2.0 from https://files.pythonhosted.org/packages/f9/0d/514be8597d7a96243e5467a37d337b9399cec117a513fcf9328405d911c0/charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/b5/03/7dec2e257bd173b5ca1f74477863b97d322149f6f0284d7decead8c5ceeb/frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting six>=1.5 (from python-dateutil->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for jsonschema-specifications>=2023.03.6 from https://files.pythonhosted.org/packages/1c/24/83349ac2189cc2435e84da3f69ba3c97314d3c0622628e55171c6798ed80/jsonschema_specifications-2023.7.1-py3-none-any.whl.metadata\n",
      "  Using cached jsonschema_specifications-2023.7.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for referencing>=0.28.4 from https://files.pythonhosted.org/packages/ea/c3/f75f0ce2cdacca3d68a70b1756635092a1add1002e34afb4895b9fb62598/referencing-0.30.0-py3-none-any.whl.metadata\n",
      "  Using cached referencing-0.30.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for rpds-py>=0.7.1 from https://files.pythonhosted.org/packages/7d/99/dde5f56b7b93eb28a2fbba393d7b48cc2fec20371fa9c11b627d97b0f900/rpds_py-0.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached rpds_py-0.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/38/6f/5382bdff9dda60cb17cef6dfa2bad3e6edacffd5c2243e282e851c63f721/contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/aa/58/9054d2d3d475c4222c084c81f6f2047c2aed31d42e706757268bb1159f69/fonttools-4.41.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached fonttools-4.41.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib->bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Using cached kiwisolver-1.4.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Collecting packaging>=20.0 (from matplotlib->bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Collecting pillow>=6.2.0 (from matplotlib->bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Obtaining dependency information for pillow>=6.2.0 from https://files.pythonhosted.org/packages/50/e5/0d484d1ac71b934638f91b7156203ba5bf3eb12f596b616a68a85c123808/Pillow-10.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata\n",
      "  Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib->bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib->bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Obtaining dependency information for importlib-resources>=3.2.0 from https://files.pythonhosted.org/packages/29/d1/bed03eca30aa05aaf6e0873de091f9385c48705c4a607c2dfe3edbe543e8/importlib_resources-6.0.0-py3-none-any.whl.metadata\n",
      "  Using cached importlib_resources-6.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn->bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/28/08/9dcdaa5aac4634e4c23af26d92121f7ce445c630efa0d3037881ae2407fb/joblib-1.3.1-py3-none-any.whl.metadata\n",
      "  Using cached joblib-1.3.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting patsy>=0.5.2 (from statsmodels->bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Collecting jsonschema (from gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting pyrsistent>=0.14.0 (from jsonschema->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/canine/lib/python3.9/site-packages (from jsonschema->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1)) (68.0.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore<0.17.0,>=0.15.0->httpx->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting anyio<5.0,>=3.0 (from httpcore<0.17.0,>=0.15.0->httpx->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for anyio<5.0,>=3.0 from https://files.pythonhosted.org/packages/19/24/44299477fe7dcc9cb58d0a57d5a7588d6af2ff403fdd2d47a246c91a3246/anyio-3.7.1-py3-none-any.whl.metadata\n",
      "  Using cached anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib->bioinfokit->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 2))\n",
      "  Obtaining dependency information for zipp>=3.1.0 from https://files.pythonhosted.org/packages/8c/08/d3006317aefe25ea79d3b76c9650afabaf6d63d1c8443b236e7405447503/zipp-3.16.2-py3-none-any.whl.metadata\n",
      "  Using cached zipp-3.16.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting typing-extensions>=3.7.4 (from typing-inspect<1,>=0.4.0->dataclasses-json->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for typing-extensions>=3.7.4 from https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting exceptiongroup (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx->gen3==4.20->-r /home/jovyan/condaenv.u83xlnk2.requirements.txt (line 1))\n",
      "  Obtaining dependency information for exceptiongroup from https://files.pythonhosted.org/packages/fe/17/f43b7c9ccf399d72038042ee72785c305f6c6fdc6231942f8ab99d995742/exceptiongroup-1.1.2-py3-none-any.whl.metadata\n",
      "  Using cached exceptiongroup-1.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Using cached gen3-4.20.0-py3-none-any.whl (162 kB)\n",
      "Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Using cached pypfb-0.5.26-py3-none-any.whl (28 kB)\n",
      "Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "Using cached dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Using cached matplotlib-3.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Using cached scikit_learn-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "Using cached scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB)\n",
      "Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB)\n",
      "Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "Using cached fastavro-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "Using cached fonttools-4.41.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\n",
      "Using cached importlib_resources-6.0.0-py3-none-any.whl (31 kB)\n",
      "Using cached joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Using cached zipp-3.16.2-py3-none-any.whl (7.2 kB)\n",
      "Using cached exceptiongroup-1.1.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: textwrap3, rfc3986, pytz, cdislogging, asyncio, zipp, xmltodict, urllib3, typing-extensions, tqdm, threadpoolctl, tabulate, sniffio, six, PyYAML, python-json-logger, pyrsistent, pyparsing, pillow, packaging, numpy, mypy-extensions, multidict, kiwisolver, joblib, idna, humanfriendly, h11, frozenlist, fonttools, fastavro, exceptiongroup, cycler, click, charset-normalizer, certifi, backoff, attrs, async-timeout, aiofiles, yarl, typing-inspect, scipy, requests, python-dateutil, patsy, marshmallow, jsonschema, importlib-resources, contourpy, anyio, aiosignal, scikit-learn, pandas, matplotlib, indexclient, httpcore, dictionaryutils, dataclasses-json, aiohttp, statsmodels, seaborn, matplotlib-venn, httpx, gdcdictionary, adjustText, drsclient, bioinfokit, pypfb, gen3\n",
      "Successfully installed PyYAML-5.4.1 adjustText-0.8 aiofiles-0.8.0 aiohttp-3.8.5 aiosignal-1.3.1 anyio-3.7.1 async-timeout-4.0.2 asyncio-3.4.3 attrs-23.1.0 backoff-1.11.1 bioinfokit-2.1.1 cdislogging-1.1.1 certifi-2023.7.22 charset-normalizer-3.2.0 click-7.1.2 contourpy-1.1.0 cycler-0.11.0 dataclasses-json-0.5.14 dictionaryutils-3.4.6 drsclient-0.2.3 exceptiongroup-1.1.2 fastavro-1.8.2 fonttools-4.41.1 frozenlist-1.4.0 gdcdictionary-1.2.0 gen3-4.20.0 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 humanfriendly-10.0 idna-3.4 importlib-resources-6.0.0 indexclient-2.2.1 joblib-1.3.1 jsonschema-3.2.0 kiwisolver-1.4.4 marshmallow-3.20.1 matplotlib-3.7.2 matplotlib-venn-0.11.9 multidict-6.0.4 mypy-extensions-1.0.0 numpy-1.25.2 packaging-23.1 pandas-1.5.3 patsy-0.5.3 pillow-10.0.0 pyparsing-3.0.9 pypfb-0.5.26 pyrsistent-0.19.3 python-dateutil-2.8.2 python-json-logger-0.1.11 pytz-2023.3 requests-2.31.0 rfc3986-1.5.0 scikit-learn-1.3.0 scipy-1.11.1 seaborn-0.12.2 six-1.16.0 sniffio-1.3.0 statsmodels-0.14.0 tabulate-0.9.0 textwrap3-0.9.2 threadpoolctl-3.2.0 tqdm-4.65.0 typing-extensions-4.7.1 typing-inspect-0.9.0 urllib3-1.26.16 xmltodict-0.13.0 yarl-1.9.2 zipp-3.16.2\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate canine\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env create --name canine --file=environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea93d81-1156-444f-b064-f15c3a372be5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65f763a-ade7-4200-8282-bcecdde11441",
   "metadata": {},
   "source": [
    "Now all that's left is to run the Nextflow process itself (the resume option is optional and tells Nextflow to use any work files leftover from previous runs when able):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0e2bd2e-ab72-4d2c-8615-f4ff4de5c004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N E X T F L O W  ~  version 22.10.6\n",
      "Launching `canine.nf` [cheeky_poisson] DSL2 - revision: 660eb25521\n",
      "[-        ] process > DownloadFastqFile -\u001b[K\n",
      "\u001b[2A\n",
      "[-        ] process > DownloadFastqFile -\u001b[K\n",
      "[-        ] process > AnalyzeFastqFile  -\u001b[K\n",
      "\u001b[3A\n",
      "executor >  local (1)\u001b[K\n",
      "[fc/086f71] process > DownloadFastqFile [  0%] 0 of 1\u001b[K\n",
      "[-        ] process > AnalyzeFastqFile  -\u001b[K\n",
      "\u001b[4A\n",
      "executor >  local (2)\u001b[K\n",
      "[fc/086f71] process > DownloadFastqFile    [100%] 1 of 1 \u001b[K\n",
      "[6d/4a6eb5] process > AnalyzeFastqFile (1) [  0%] 0 of 1\u001b[K\n",
      "\u001b[4A\n",
      "executor >  local (2)\u001b[K\n",
      "[fc/086f71] process > DownloadFastqFile    [100%] 1 of 1 \u001b[K\n",
      "[6d/4a6eb5] process > AnalyzeFastqFile (1) [100%] 1 of 1 \u001b[K\n",
      "\u001b[32;1mCompleted at: 31-Jul-2023 19:26:50\n",
      "Duration    : 1m 11s\n",
      "CPU hours   : (a few seconds)\n",
      "Succeeded   : 2\n",
      "\u001b[22;39m\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nextflow run canine.nf --resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d87e10e-a6c9-4794-94a3-9f090a80e7f6",
   "metadata": {},
   "source": [
    "Nextflow lists the process or processes it is running at any point when it is running via command-line output (displayed above). The hash corresponding to each process is displayed to the left of the process itself. At the end of its execution, Nextflow also returns the time-stamp of the workflow execution, the workflow real-time execution time, the time the workflow took on the devices used for execution, and the number of processes which ran successfullly at the end of its command-line output.\n",
    "\n",
    "When the script is run, Nextflow creates a directory structure to manage the data and workflow execution. Here is a breakdown of the resulting directory structure:\n",
    "\n",
    "1. `work/`: This directory is automatically created by Nextflow and is where the program runs the processes. Inside the `work/` directory, there will be multiple subdirectories, each corresponding to a process task. Each subdirectory will be named with a hash value, unique to each task (and its corresponding process). Inside these task directories, Nextflow stores scripts, input files, and output files related to each task. \n",
    "\n",
    "2. `results/`: This directory is specified in the `AnalyzeFastqFile` process with the `publishDir` directive. This is where the output files of the `AnalyzeFastqFile` process will be copied to.\n",
    "\n",
    "    - `results/SRR7012463_1.fastq_analysis.txt`: This file is the output of the `AnalyzeFastqFile` process. It contains the analysis of the FASTQ file and is copied into the `results/` directory.\n",
    "\n",
    "The file `SRR7012463_1.fastq` downloaded from the `DownloadFastqFile` process is not specified to be copied or moved to a specific location, so it will also remain within its `work/` subdirectory. This file is not copied from its work directories since it is extremely large and is likely to exhaust memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
