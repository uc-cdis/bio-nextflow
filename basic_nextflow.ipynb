{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c9f5ca-6244-470d-bddb-681f70d7e229",
   "metadata": {},
   "source": [
    "*This tutorial provides a summarized explanation of Nextflow, derived from the original Nextflow training documents available at https://training.nextflow.io/. In addition, it also showcases an interactive example of how to utilize Nextflow in BRH adapted from the Canine Data Commons FASTQ Reader tutorial at https://brh.data-commons.org/dashboard/Public/notebooks/canine_datacommons_fastq_reader.html.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bdca20-1369-4b62-857f-4ab0b19fae18",
   "metadata": {},
   "source": [
    "In order for this tutorial to be able to download data from Gen3, access to the Tutorial CANINE Google Login must be authorized under the Profile page in BRH. Read more at https://brh.data-commons.org/dashboard/Public/index.html#LinkingAccessTo ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b1378c-5bbf-4b67-97ca-79e092521694",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Nextflow Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dedd8dd-ebd8-4d0e-aac9-6072ce2f4f1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Why Use Nextflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884692a-9af0-49f7-ac92-f8efbfe761df",
   "metadata": {},
   "source": [
    "Nextflow is a tool that helps to easily create workflows for data-heavy computations. It's built around the idea that Linux, with its many command-line and scripting tools, is an ideal language for data science. \n",
    "\n",
    "Nextflow allows you to define complex interactions between programming languages and gives you a sophisticated parallel computing environment in which to write data science pipelines (termed workflows). It's key features include:\n",
    "* Workflow portability and reproducibility\n",
    "* Scalability of parallelization and deployment\n",
    "* Integration of existing tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90939c02-3405-4779-8c9b-5aff028038c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Processes and Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3bf59-80e1-4e16-9ac7-7b2bab3d2217",
   "metadata": {},
   "source": [
    "A Nextflow workflow is created by connecting different processes. Each process can be written in any scripting language that Linux can run (like Bash, Perl, Ruby, Python, etc.). These processes run independently and do not share any common state that can be written to.\n",
    "\n",
    "The only way these processes can talk to each other is through asynchronous queues called channels. Any process can define one or more channels as an input and output. The way these processes interact, and therefore the workflow itself, is determined by these input and output declarations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ad1a6-46d6-4b7c-9757-c3de0a7cd0d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execution Abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afedc7-a964-4f77-accb-ef514b8dae47",
   "metadata": {},
   "source": [
    "While a process defines what command or script should be run, the executor determines how that script is run on the target platform. Unless specified otherwise, processes are run on your local computer.\n",
    "\n",
    "However, for real-world workflows, high-performance computing (HPC) or a cloud platform is often needed. Nextflow provides a separation between the logic of the workflow and the system on which it runs. This means you can create a workflow that runs on your computer, a server, or the cloud, without needing any changes. You just need to define the target platform in the configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0534fb-475f-4be0-8531-b297ace0af5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scripting Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa134dd6-7900-42c1-9dfd-b2f483a2d00c",
   "metadata": {},
   "source": [
    "Nextflow scripting is an extension of the Groovy programming language, which itself is a subset of Java. Groovy is like a simplified version of Java, making it easier and more approachable to write code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc302c3-b375-4e43-b464-e664d16b732f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example Gen3 Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4729a651-4b47-40d5-928c-104aa30c5708",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60214f6a-3233-4e92-9a01-6058fcb4b178",
   "metadata": {},
   "source": [
    "Now let's get into the specifics of how Nextflow works. The most essential component of a Nextflow workflow is the main .nf Nextflow script file. Here is where the main flow of the workflow is set. We will slowly build up the components of this file in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9219c1-3714-446c-adf4-e8d6bdac1968",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/usr/bin/env nextflow\n",
    "...\n",
    "workflow {\n",
    "    file = DownloadFastqFile()\n",
    "    AnalyzeFastqFile(file)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa29550-0ff5-48a8-ae8a-d3a345c75ebe",
   "metadata": {},
   "source": [
    "The first line of a Nextflow script file is a shebang. It is a special kind of comment used in scripts that tells the system what interpreter to use to execute the script. \n",
    "\n",
    "In this case, `#!/usr/bin/env nextflow` indicates that the script should be run using the `nextflow` interpreter. The `env` command is used to find the `nextflow` interpreter in the system's PATH. If you are using a Nextflow workspace in BRH then this has already been properly set-up. Otherwise refer to https://www.nextflow.io/docs/latest/getstarted.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c2c134-9915-4ee7-b304-66f42c290b1d",
   "metadata": {},
   "source": [
    "The workflow is the last component of the Nextflow script and consists of the main steps in the workflow:\n",
    "\n",
    "1. `file = DownloadFastqFile()`: This line calls the `DownloadFastqFile` process, which is defined earlier in the script (but omitted in the ellipses here for clarity). The result of this process is stored in the variable `file`.\n",
    "\n",
    "3. `AnalyzeFastqFile(file)`: This line calls the `AnalyzeFastqFile` process, using the input of `DownloadFastqFile`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d1587d-1bc6-4c33-be2d-fa32b2909606",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/usr/bin/env nextflow\n",
    "\n",
    "params.fastq_file = \"SRR7012463_1.fastq\" // Name of retreived file\n",
    "params.fastq_guid = \"dg.C78ne/4527012c-3a5f-481d-820c-da7b77a26b48\"\n",
    "params.max_records = 10 // max records to process\n",
    "params.endpoint = \"https://caninedc.org\"\n",
    "params.refresh_file = \"/home/jovyan/.gen3/credentials.json\"\n",
    "...\n",
    "workflow {\n",
    "    file = DownloadFastqFile()\n",
    "    AnalyzeFastqFile(file)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c065e-f04c-42d3-b2a7-e571bff4c287",
   "metadata": {},
   "source": [
    "These next lines of code are setting up some default parameters for the Nextflow script. These parameters can be used within the script and can also be overridden when you run the script. \n",
    "\n",
    "You can set or override the parameters when you run the script by passing them as command line arguments with the `--` prefix. \n",
    "\n",
    "For example, to run the script with different values for `fastq_file` and `max_records`, you would use the following command:\n",
    "\n",
    "```bash\n",
    "nextflow run canine.nf --fastq_file=\"NewFile.fastq\" --max_records=20\n",
    "```\n",
    "\n",
    "`nextflow run canine.nf` is the ordinary syntax for running the script, `NewFile.fastq` is the new value for `fastq_file` and `20` is the new value for `max_records`. \n",
    "\n",
    "This is one of the features that makes Nextflow powerful for pipeline scripting. By using parameters, the same script can be used with different data or settings without any changes to the script itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7b26a-4a1f-49fd-adde-a1c740aabd73",
   "metadata": {},
   "source": [
    "The workflow showcased here consists of two separate processes. The first of these is `DownloadFastqFile`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc7f2a-2d9d-45ea-9d69-96e79e89becb",
   "metadata": {},
   "source": [
    "```bash\n",
    "process DownloadFastqFile {\n",
    "    \n",
    "    conda './environment.yml' // path to your environment.yml file\n",
    "\n",
    "    output:\n",
    "    path(\"${params.fastq_file}\")\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    gen3 drs-pull object \"${params.fastq_guid}\"\n",
    "    gunzip \"${params.fastq_file}\".gz\n",
    "    \"\"\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd3cf6-592e-4f67-8125-a0c8308a9746",
   "metadata": {},
   "source": [
    "This process consists of several major components:\n",
    "\n",
    "1. `conda './environment.yml'`: This is an optional line which tells Nextflow to use the conda environment specified in the 'environment.yml' file to run this process (or create it if it doesn't already exist). Conda is a package and environment management system, and using this statement ensures that the correct dependencies are installed and used for this process. It is also possible to specify the conda environment to be used in the nextflow configuration file instead (see below for more details on the Nextflow configuration file).\n",
    "\n",
    "2. `output: path(\"${params.fastq_file}\")`: This line specifies what the process will output. In this case, the process outputs the file that was downloaded and whose name is given by the parameter `params.fastq_file`.\n",
    "\n",
    "3. `script:`: This begins the section where the commands to be run by this process are defined. In this case the commands are bash script to download the `params.fastq_file` file from gen3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90093015-71e2-4704-bd36-e10fe85f8075",
   "metadata": {},
   "source": [
    "The `./environment.yml` file being used to specify the conda environment installs the needed dependencies for the python scripts being run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345a7d88-3486-4da1-aaad-74d9a4936f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile environment.yml\n",
    "name: canine\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.9\n",
    "  - pip\n",
    "  - pip:\n",
    "    - gen3==4.13.0\n",
    "    - bioinfokit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59941ea-c86e-4fe0-9a6b-e57e30ddbc15",
   "metadata": {},
   "source": [
    "*Note the `%%writefile environment.yml` line tells Jupyter Notebook to write the cell to a file rather than running the code in Jupyter Notebook*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c0771-8327-4891-8001-cfd88a12dc75",
   "metadata": {},
   "source": [
    "Read more about conda environment files at https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76cf344-6e8c-4aa6-8092-f828b3f00b80",
   "metadata": {},
   "source": [
    "The Nextflow configuration file gives additional setup details for the Nextflow workflow. In this case, it only needs to specify that Conda is to be used for setting up the environments for the individuals processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06016bb7-5398-494b-bfd0-eefd48ee1b55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nextflow.config\n"
     ]
    }
   ],
   "source": [
    "%%writefile nextflow.config\n",
    "// enables the processes to be run in a conda environment\n",
    "conda.enabled = true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8b5830-0fce-4f34-b6fe-70b962cd1cc9",
   "metadata": {},
   "source": [
    "Nextflow configuration files can specify variables for the script being run or specific settings for how to run the script. Read more about Nextflow configuration files at https://www.nextflow.io/docs/latest/config.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef10ae-43a4-4383-b1e9-076f061fcd6a",
   "metadata": {},
   "source": [
    "```bash\n",
    "process AnalyzeFastqFile {\n",
    "\n",
    "    // Copy the outputs of AnalyzeFastqFile to the results directory in\n",
    "    // the base workflow directory\n",
    "    publishDir \"${baseDir}/results\", mode: 'copy'\n",
    "    \n",
    "    conda './environment.yml' // path to your environment.yml file\n",
    "\n",
    "    input:\n",
    "    path(\"${params.fastq_file}\")\n",
    "\n",
    "    output:\n",
    "    path(\"${params.fastq_file}_analysis.txt\")\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    python3 ${baseDir}/analyze_fastq.py ${params.endpoint} ${params.refresh_file} ${params.fastq_file} ${params.max_records}\n",
    "    \"\"\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33650e1c-6981-4296-a313-33f8736445cc",
   "metadata": {},
   "source": [
    "The second process in this workflow takes the file specified by the parameter `params.fastq_file` and runs the Python script `analyze_fastq.py` which can be found in the same directory as the Nextflow script (this is indicated by the `${baseDir}/` before the name of the Python script to be run).\n",
    "\n",
    "The `analyze_fastq.py` script is run with four command-line parameters each of which is specified by one of the earlier specified `params`. The reason that the file needs to be passed as an input to the `AnalyzeFastqFile` script in addition to being specified as a command-line parameter for the Python script is that specifying the file as an input to the process indicates to Nextflow that that file must be created before this script can be run while feeding the name of the file as a command-line parameter of the Python script indicates to the Python script what file name to use in its analysis.\n",
    "\n",
    "Lastly, the AnalyzeFastqFile process also specifies `${params.fastq_file}_analysis.txt` as the output of the `analyze_fastq.py`. The actual code to create the file is within the Python script itself but this section indicates to the process to expect a text file named `${params.fastq_file}_analysis.txt` to be written by the Python script. The line `publishDir \"${baseDir}/results\", mode: 'copy'` indicates for Nextflow to copy the `${params.fastq_file}_analysis.txt` file produced by this process to the results folder in the same main directory as the Nextflow script (`${baseDir}`). This line will also automatically create a results folder for the output to be copied into if one doesn't already exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7bee7-bf44-4c3a-be65-a6e535b4cb85",
   "metadata": {},
   "source": [
    "The Python code for the AnalyzeFastqFile process is given in `analyze_fastq.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e51afc1-d7e8-49ac-be04-a0ece8140e52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting analyze_fastq.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile analyze_fastq.py\n",
    "import sys\n",
    "from gen3.file import Gen3File\n",
    "from gen3.query import Gen3Query\n",
    "from gen3.auth import Gen3Auth\n",
    "from gen3.submission import Gen3Submission\n",
    "from gen3.index import Gen3Index\n",
    "from bioinfokit.analys import fastq\n",
    "\n",
    "endpoint = sys.argv[1]\n",
    "auth = Gen3Auth(endpoint, refresh_file = sys.argv[2])\n",
    "sub = Gen3Submission(endpoint, auth)\n",
    "file = Gen3File(endpoint, auth)\n",
    "\n",
    "programs = sub.get_programs()\n",
    "\n",
    "records = fastq.fastq_reader(file=sys.argv[3])\n",
    "counter = 0\n",
    "output_file = open(sys.argv[3] + \"_analysis.txt\", \"w\")\n",
    "\n",
    "for record in records:\n",
    "    if counter < float(sys.argv[4]):\n",
    "        _, sequence, _, quality = record\n",
    "        base_count = {'A': sequence.count('A'), 'C': sequence.count('C'), 'G': sequence.count('G'), 'T': sequence.count('T')}\n",
    "        output_file.write(f\"{sequence}, {quality}, {base_count}\\n\")\n",
    "    else:\n",
    "        break\n",
    "    counter += 1\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa76588f-b9b8-4f24-9447-9bbf69b4725c",
   "metadata": {},
   "source": [
    "This script, `analyze_fastq.py`, analyzes a FASTQ file and outputs a textual analysis to a new file. The analysis includes the sequence, quality, and base counts for a certain number of records. The FASTQ file to be analyzed, the number of records to be analyzed, and some additional parameters are passed to the script as command-line arguments.\n",
    "\n",
    "1. `import sys`: This imports the `sys` module, which will be used to retrieve command-line arguments.\n",
    "\n",
    "2. The script then imports several modules from the `gen3` and `bioinfokit` packages, which will be used to interact with a Gen3 data repository and to analyze the FASTQ file, respectively.\n",
    "\n",
    "3. `endpoint = sys.argv[1]`: This line sets the `endpoint` variable to the first command-line argument. This is presumably the URL of the Gen3 data repository to be accessed.\n",
    "\n",
    "4. `auth = Gen3Auth(endpoint, refresh_file = sys.argv[2])`: This line creates a `Gen3Auth` object, which represents the user's authorization to access the Gen3 data repository. The `refresh_file` argument is the second command-line argument and should point to a file that contains the user's credentials.\n",
    "\n",
    "5. `sub = Gen3Submission(endpoint, auth)`: This line creates a `Gen3Submission` object, which can be used to submit data to the Gen3 repository.\n",
    "\n",
    "6. `file = Gen3File(endpoint, auth)`: This line creates a `Gen3File` object, which represents the file to be analyzed.\n",
    "\n",
    "7. `programs = sub.get_programs()`: This line gets a list of programs from the Gen3 repository. By printing the `programs` variable one can see the programs under the main repository umbrella.\n",
    "\n",
    "8. `records = fastq.fastq_reader(file=sys.argv[3])`: This line reads the records from the FASTQ file, which is the third command-line argument.\n",
    "\n",
    "9. The `counter` variable is initialized to zero, and `output_file` is opened for writing. The output file's name is the same as the input FASTQ file with \"_analysis.txt\" appended to it.\n",
    "\n",
    "10. In the for loop, the script iterates over the FASTQ records. For each record, it splits the record into its sequence and quality components. It then counts the number of each base (A, C, G, T) in the sequence. This information is written to the output file. The loop stops when the number of processed records equals the fourth command-line argument (`sys.argv[4]`).\n",
    "\n",
    "11. `output_file.close()`: Finally, the script closes the output file.\n",
    "\n",
    "So, in summary, this script (and consequently the `AnalyzeFastqFile` process which calls it) reads a FASTQ file, analyzes the sequence and quality of a certain number of records, and writes the results to a new file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08daf31f-ba0f-49e3-9328-4c9f486d06d0",
   "metadata": {},
   "source": [
    "Putting all sections of the Nextflow script together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1afb713d-83b3-40ef-baa6-553753969f53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting canine.nf\n"
     ]
    }
   ],
   "source": [
    "%%writefile canine.nf\n",
    "#!/usr/bin/env nextflow\n",
    "\n",
    "params.fastq_file = \"SRR7012463_1.fastq\" // Name of retreived file\n",
    "params.fastq_guid = \"dg.C78ne/4527012c-3a5f-481d-820c-da7b77a26b48\" // GUID for fastq file\n",
    "params.max_records = 10 // max records to process\n",
    "params.endpoint = \"https://caninedc.org\"\n",
    "params.refresh_file = \"/home/jovyan/.gen3/credentials.json\"\n",
    "\n",
    "process DownloadFastqFile {\n",
    "\n",
    "    // Move the outputs of DownloadFastqFile to the results directory in\n",
    "    // the base workflow directory\n",
    "    \n",
    "    conda './environment.yml' // path to your environment.yml file\n",
    "\n",
    "    output:\n",
    "    path(\"${params.fastq_file}\")\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    gen3 drs-pull object \"${params.fastq_guid}\"\n",
    "    gunzip \"${params.fastq_file}\".gz\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "process AnalyzeFastqFile {\n",
    "\n",
    "    // Copy the outputs of AnalyzeFastqFile to the results directory in\n",
    "    // the base workflow directory\n",
    "    publishDir \"${baseDir}/results\", mode: 'copy'\n",
    "    \n",
    "    conda './environment.yml' // path to your environment.yml file\n",
    "\n",
    "    input:\n",
    "    path(\"${params.fastq_file}\")\n",
    "\n",
    "    output:\n",
    "    path(\"${params.fastq_file}_analysis.txt\")\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    python3 ${baseDir}/analyze_fastq.py ${params.endpoint} ${params.refresh_file} ${params.fastq_file} ${params.max_records}\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "workflow {\n",
    "    file = DownloadFastqFile()\n",
    "    AnalyzeFastqFile(file)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c19fd-6753-4ffc-9565-9c06fc4baeeb",
   "metadata": {},
   "source": [
    "To edit and re-run the Nextflow script, make sure to execute the above cell again to rewrite the Nextflow script file and then run the code block following this to re-run the script itself. It may also be necessary to delete the work and results directory between runs since the large size of the downloaded `SRR7012463_1.fastq` file can quickly exhaust memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea93d81-1156-444f-b064-f15c3a372be5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65f763a-ade7-4200-8282-bcecdde11441",
   "metadata": {},
   "source": [
    "Now all that's left is to run the Nextflow process itself (the resume option is optional and tells Nextflow to use any work files leftover from previous runs when able):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e2bd2e-ab72-4d2c-8615-f4ff4de5c004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N E X T F L O W  ~  version 22.10.6\n",
      "[3.016s][warning][jni,resolve] Re-registering of platform native method: java.lang.PanwHooksNs.HookArgs0()V from code in a different classloader\n",
      "[3.016s][warning][jni,resolve] Re-registering of platform native method: java.lang.PanwHooksNs.HookArgs1(Ljava/lang/Object;)V from code in a different classloader\n",
      "[3.016s][warning][jni,resolve] Re-registering of platform native method: java.lang.PanwHooksNs.HookArgs2(Ljava/lang/Object;Ljava/lang/Object;)V from code in a different classloader\n",
      "[3.016s][warning][jni,resolve] Re-registering of platform native method: java.lang.PanwHooksNs.HookArgs3(Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/Object;)V from code in a different classloader\n",
      "[3.017s][warning][jni,resolve] Re-registering of platform native method: java.lang.PanwHooksNs.HookArgs4(Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/Object;)V from code in a different classloader\n",
      "Launching `canine.nf` [ecstatic_mirzakhani] DSL2 - revision: 78346020c4\n",
      "[-        ] process > DownloadFastqFile -\u001b[K\n",
      "[-        ] process > AnalyzeFastqFile  -\u001b[K\n",
      "\u001b[3A\n",
      "[-        ] process > DownloadFastqFile -\u001b[K\n",
      "[-        ] process > AnalyzeFastqFile  -\u001b[K\n",
      "Creating env using conda: ./environment.yml [cache /home/jovyan/pd/work/conda/canine-99179bc49932240ebc733d72b9f23f31]\u001b[K\n",
      "\u001b[4A\n",
      "executor >  local (1)\u001b[K\n",
      "[9d/063f2f] process > DownloadFastqFile [  0%] 0 of 1\u001b[K\n",
      "[-        ] process > AnalyzeFastqFile  -\u001b[K\n",
      "\u001b[K\n",
      "\u001b[5A\n",
      "executor >  local (1)\u001b[K\n",
      "[9d/063f2f] process > DownloadFastqFile [100%] 1 of 1 笨能u001b[K\n",
      "[-        ] process > AnalyzeFastqFile  [  0%] 0 of 1\u001b[K\n",
      "\u001b[K\n",
      "\u001b[5A\n",
      "executor >  local (2)\u001b[K\n",
      "[9d/063f2f] process > DownloadFastqFile [100%] 1 of 1 笨能u001b[K\n",
      "[10/c05464] process > AnalyzeFastqFile  [  0%] 0 of 1\u001b[K\n",
      "\u001b[4A\n",
      "executor >  local (2)\u001b[K\n",
      "[9d/063f2f] process > DownloadFastqFile [100%] 1 of 1 笨能u001b[K\n",
      "[10/c05464] process > AnalyzeFastqFile  [100%] 1 of 1 笨能u001b[K\n",
      "\u001b[32;1mCompleted at: 20-Jun-2023 23:49:55\n",
      "Duration    : 2m 13s\n",
      "CPU hours   : (a few seconds)\n",
      "Succeeded   : 2\n",
      "\u001b[22;39m\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nextflow run canine.nf --resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d87e10e-a6c9-4794-94a3-9f090a80e7f6",
   "metadata": {},
   "source": [
    "Nextflow lists the process or processes it is running at any point when it is running via command-line output (displayed above). The hash corresponding to each process is displayed to the left of the process itself. At the end of its execution, Nextflow also returns the time-stamp of the workflow execution, the workflow real-time execution time, the time the workflow took on the devices used for execution, and the number of processes which ran successfullly at the end of its command-line output.\n",
    "\n",
    "When the script is run, Nextflow creates a directory structure to manage the data and workflow execution. Here is a breakdown of the resulting directory structure:\n",
    "\n",
    "1. `work/`: This directory is automatically created by Nextflow and is where the program runs the processes. Inside the `work/` directory, there will be multiple subdirectories, each corresponding to a process task. Each subdirectory will be named with a hash value, unique to each task (and its corresponding process). Inside these task directories, Nextflow stores scripts, input files, and output files related to each task. \n",
    "\n",
    "2. `results/`: This directory is specified in the `AnalyzeFastqFile` process with the `publishDir` directive. This is where the output files of the `AnalyzeFastqFile` process will be copied to.\n",
    "\n",
    "    - `results/SRR7012463_1.fastq_analysis.txt`: This file is the output of the `AnalyzeFastqFile` process. It contains the analysis of the FASTQ file and is copied into the `results/` directory.\n",
    "\n",
    "The file `SRR7012463_1.fastq` downloaded from the `DownloadFastqFile` process is not specified to be copied or moved to a specific location, so it will also remain within its `work/` subdirectory. This file is not copied from its work directories since it is extremely large and is likely to exhaust memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
